{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    " You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the require libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\myids\\OneDrive\\Documents\\Python Scripts\\chromedriver.exe\")\n",
    "driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#here we have to scrap information from the table.\n",
    "#initially we will scrap the all the rows excluding headings.\n",
    "#then we will srap all  the columns ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#web elements for all the rows by Xpath functon\n",
    "row=1+len(driver.find_elements_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[3]/tbody/tr\"))\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "for r in range(1,row):\n",
    "    try:    #Name\n",
    "        for n in driver.find_elements_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[3]/tbody/tr[\"+str(r)+\"]/td[1]\"):\n",
    "            Rank.append(n.text)\n",
    "    except NoSuchElementException:\n",
    "        Rank.append(\"-\")\n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "for r in range(1,row):\n",
    "    try:    #Name\n",
    "        for n in driver.find_elements_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[3]/tbody/tr[\"+str(r)+\"]/td[2]\"):\n",
    "            Name.append(n.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append(\"-\")\n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Artist=[]\n",
    "for r in range(1,row):\n",
    "    try:    #Artist\n",
    "        for n in driver.find_elements_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[3]/tbody/tr[\"+str(r)+\"]/td[3]\"):\n",
    "            Artist.append(n.text)\n",
    "    except NoSuchElementException:\n",
    "        Artist.append(\"-\")\n",
    "Artist        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Upload_date=[]\n",
    "for r in range(1,row):\n",
    "    try:    #Upload_date\n",
    "        for n in driver.find_elements_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[3]/tbody/tr[\"+str(r)+\"]/td[5]\"):\n",
    "            Upload_date.append(n.text)\n",
    "    except NoSuchElementException:\n",
    "         Upload_date.append(\"-\")\n",
    "Upload_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Views=[]\n",
    "for r in range(1,row):\n",
    "    try:    #Views_\n",
    "        for n in driver.find_elements_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[3]/tbody/tr[\"+str(r)+\"]/td[4]\"):\n",
    "            Views.append(n.text)\n",
    "    except NoSuchElementException:\n",
    "        Views.append(\"-\")\n",
    "        \n",
    "Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Rank']=Rank\n",
    "df['Name']=Name\n",
    "df['Artist']=Artist\n",
    "df['Upload date']=Upload_date\n",
    "df['Views']=Views\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#connect to web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\myids\\OneDrive\\Documents\\Python Scripts\\chromedriver.exe\")\n",
    "driver\n",
    "url='https://www.bcci.tv/international/fixtures'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[] \n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match_title\n",
    "try:\n",
    "    for t in  driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__format']\"):\n",
    "        Match_title.append(t.text)\n",
    "except NoSuchElementException:\n",
    "    Match_title.append(\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Series\n",
    "try:\n",
    "    for s in driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__tournament-label u-truncated']\"):\n",
    "        Series.append(s.text)\n",
    "except NoSuchElementException:\n",
    "    Series.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place\n",
    "try:\n",
    "    for p in driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']//span\"):\n",
    "        Place.append(p.text)\n",
    "except NoSuchElementException:\n",
    "    Place.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date\n",
    "try:\n",
    "    for d in driver.find_elements_by_xpath(\"//span[@class='fixture__datetime tablet-only']//strong\"):\n",
    "        Date.append(d.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append(\"_\")\n",
    "    \n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    Date.append(\"_\")\n",
    "Date     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Match_title']=Match_title\n",
    "df['Series']=Series\n",
    "df['Place']=Place\n",
    "df['Date']= Date\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\myids\\OneDrive\\Documents\\Python Scripts\\chromedriver.exe\")\n",
    "url='https://www.guru99.com/'\n",
    "driver.get(url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on selenium\n",
    "#driver.find_element_by_xpath(\"//*[@id=\"java_technologies\"]/li[3]/a\").click()\n",
    "driver.find_elements_by_xpath(\"//span[@class='kadence-svg-iconset']\")[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select and click selenium exception handling\n",
    "driver.find_element_by_xpath('/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[2]/div[1]/div/ul[1]/li[3]/a')\n",
    "#driver.find_element_by_xpath('/html/body/div[2]/section[3]/div/div[1]/main/div/div/div/div/div/div/div[2]/table[5]/tbody/tr[34]/td[1]/a').click()\n",
    "searchBar=driver.find_element_by_xpath(\"//input[@class='gsc-input']\")\n",
    "searchBar.send_keys(\"selenium exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=1+len(driver.find_elements_by_xpath('/html/body/div[2]/section[3]/div/div[1]/main/div[1]/div/div/div/div/div/div[2]/table/tbody/tr'))\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exception_names=[]\n",
    "for r in range(2,rows):\n",
    "    for c in driver.find_elements_by_xpath(\"/html/body/div[2]/section[3]/div/div[1]/main/div[1]/div/div/div/div/div/div[2]/table/tbody/tr[\"+str(r)+\"]/td[1]\"):\n",
    "        Exception_names.append(c.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exception_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Description=[]\n",
    "for r in range(2,rows):\n",
    "    for c in driver.find_elements_by_xpath(\"/html/body/div[2]/section[3]/div/div[1]/main/div[1]/div/div/div/div/div/div[2]/table/tbody/tr[\"+str(r)+\"]/td[2]\"):\n",
    "        Description.append(c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Name']=Exception_names\n",
    "df['Description']=Description\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "economyTag=driver.find_elements_by_xpath(\"//button[@class='dropbtn']\")\n",
    "economyTag[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    IndiaTag=driver.find_elements_by_xpath(\"//div[@class='dropdown-content']/a\")\n",
    "    driver.get(IndiaTag[4].get_attribute('href'))\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(driver.find_elements_by_xpath(\"//a[@class='ec']\")[13].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "state=[]\n",
    "GSDP=[]\n",
    "GSDP18_19=[]\n",
    "try:\n",
    "    rankTag=driver.find_elements_by_xpath(\"//td[@class='data1']\")\n",
    "    Rank.extend([i.text for i in rankTag[:33]])\n",
    "    state.extend([i.text for i in driver.find_elements_by_xpath(\"//td[@class='name']\")][:33])\n",
    "    GSDP18_19.extend([i.text for i in driver.find_elements_by_xpath(\"//td[@class='data sorting_1']\")][:33])\n",
    "    GSDP.extend([i.text for i in driver.find_elements_by_xpath(\"//td[@class='data']\")][:165])\n",
    "except:\n",
    "    Rank.append(\"-\")\n",
    "    state.append(\"-\")\n",
    "    GSDP.append(\"-\")\n",
    "    GSDP18_19.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSDP19_20=GSDP[::5]\n",
    "GSDP19_20\n",
    "Share=GSDP[1::5]\n",
    "GDP=GSDP[2::5]\n",
    "GSDPat11_12_1920=GSDP[3::5]\n",
    "GSDPat11_12_1819=GSDP[4::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['Rank']=Rank\n",
    "df['State']=state\n",
    "df['GSDP (Cr INR at Current prices) 19-20']=GSDP19_20\n",
    "df['GSDP (Cr INR at Current prices) 18-19']=GSDP18_19\n",
    "df['shares']=Share\n",
    "df['GDP ($billion)']=GDP\n",
    "df['GSDP (Cr INR at 2011-12 prices) 19-20']=GSDPat11_12_1920\n",
    "df['GSDP (Cr INR at 2011-12 prices) 18-19']=GSDPat11_12_1819"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://github.com/explore\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on trending\n",
    "driver.find_element_by_xpath('/html/body/div[4]/main/div[1]/nav/div/a[3]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reprository Title\n",
    "Repository_title=[]\n",
    "for i in driver.find_elements_by_xpath(\"//h1[@class='Repository title']\"):\n",
    "    Repository_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Url=[]\n",
    "for u in driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']//a\"):\n",
    "    Url.append(u.get_attribute('href'))\n",
    "    \n",
    "Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on ist \n",
    "driver.find_element_by_xpath('/html/body/div[4]/main/div[3]/div/div[2]/article[1]/h1/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_title=[] \n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Url:\n",
    "    driver.get(i)\n",
    "    \n",
    "    try:   #Repository_title=[]\n",
    "        i= driver.find_element_by_xpath(\"//strong[@class='mr-2 flex-self-stretch']//a\")\n",
    "        Repository_title.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_title.append(\"-\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Url:\n",
    "    driver.get(i)\n",
    "    \n",
    "    try: #Repository_description=[]\n",
    "        r= driver.find_element_by_xpath(\"//div[@class='Box-body px-5 pb-5']\")\n",
    "        Repository_description.append(r.text)\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "            Repository_description.append('-') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Url:\n",
    "    driver.get(i)\n",
    "    \n",
    "    try:\n",
    "        c= driver.find_element_by_xpath(\"/html/body/div[4]/div/main/div[2]/div/div/div[2]/div[2]/div/div[4]/div/h2/a/span\")\n",
    "        Contributors_count.append(c.text)\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "         Contributors_count.append(\"-\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Language_used=[]\n",
    "for l in Url:\n",
    "    driver.get(l)\n",
    "    \n",
    "    try:\n",
    "        l= driver.find_element_by_xpath('/html/body/div[4]/div/main/div[2]/div/div/div[2]/div[2]/div/div[3]/div/ul')\n",
    "        Language_used.append(l.text)  \n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        Language_used.append(\"-\")\n",
    "        \n",
    "       \n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Repository_title']=Repository_title\n",
    "df['Repository_description']=Repository_description\n",
    "df['Contributors_count']=Contributors_count\n",
    "df['Language_used']=Language_used\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\myids\\OneDrive\\Documents\\Python Scripts\\chromedriver.exe\")\n",
    "driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.billboard.com/charts\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the view chart option\n",
    "driver.find_element_by_xpath(\"/html/body/div[3]/header/div[1]/div/div/div[2]/div/nav/ul/li[1]\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Song_name=[]\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\"):\n",
    "        Song_name.append(i.text)\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Song_name.append(\"_\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Artist_name=[]\n",
    "try:\n",
    "    for a in driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\"):\n",
    "        Artist_name.append(a.text)\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Artist_name.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last_week_rank=[]\n",
    "try:\n",
    "    for r in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\"):\n",
    "        Last_week_rank.append(r.text)\n",
    "\n",
    "except NoSuchElementException:\n",
    "    Last_week_rank.append(\"-\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Peak_rank=[]\n",
    "try:\n",
    "    for p in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\"):\n",
    "        Peak_rank.append(p.text)\n",
    "except NoSuchElementException:  \n",
    "    Peak_rank.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weeks_on_board=[]\n",
    "try:\n",
    "    for w in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\"):\n",
    "        Weeks_on_board.append(w.text)\n",
    "except NoSuchElementException:\n",
    "    Weeks_on_board.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Song_name']=Song_name\n",
    "df['Artist_name']=Artist_name\n",
    "df['Last_week_rank']=Last_week_rank\n",
    "df['Peak_rank']=Peak_rank\n",
    "df['Weeks_on_board']=Weeks_on_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\myids\\OneDrive\\Documents\\Python Scripts\\chromedriver.exe\")\n",
    "driver\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(driver.find_element_by_xpath(\"//a[@title='Search Recruiters']\").get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/div/ul[1]/li[2]/a/div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//input[@class='sugInp']\").send_keys(\"Data Science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//button[@class='fl qsbSrch blueBtn']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills_hire=[]\n",
    "Location=[]\n",
    "try:\n",
    "    nameTag=driver.find_elements_by_xpath(\"//span[@class='fl ellipsis']\")\n",
    "    Name.extend([i.text for i in nameTag])\n",
    "except:\n",
    "    Name.append(\"-\")\n",
    "try:\n",
    "    desTag=driver.find_elements_by_xpath(\"//span[@class='ellipsis clr']\")\n",
    "    Designation.extend([i.text for i in desTag])\n",
    "except:\n",
    "    Designation.append(\"-\")\n",
    "\n",
    "try:\n",
    "    comTag=driver.find_elements_by_xpath(\"//a[@class='ellipsis']\")[1::2]\n",
    "    Company.extend([i.text for i in comTag])\n",
    "except:\n",
    "    Company.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    skill=driver.find_elements_by_xpath(\"//div[@class='hireSec highlightable']\")\n",
    "    Skills_hire.extend([i.text for i in skill])\n",
    "except:\n",
    "    Skills_hire.append(\"-\")\n",
    "\n",
    "try:\n",
    "    locTag=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "    try:\n",
    "        Location.extend([i.text for i in locTag])\n",
    "    except:\n",
    "        Location.append(\"-\")\n",
    "except:\n",
    "    Location.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df[\"name\"]=Name\n",
    "df['Designation']=Designation\n",
    "df['Company']=Company\n",
    "df['Skills_hireFor']=Skills_hire\n",
    "df['Location']=Location\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q_8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=' https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row\n",
    "row=1+len(driver.find_elements_by_xpath('/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(1,row):\n",
    "    try:    #Book_name=[]\n",
    "        \n",
    "        for b in driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[\"+str(r)+\"]/td[2]\"):\n",
    "            Book_name.append(b.text)\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        Book_name.append(\"-\")\n",
    "        \n",
    "    \n",
    "    try:    #Author_name=[]\n",
    "        \n",
    "        for a in driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[\"+str(r)+\"]/td[3]\"):\n",
    "            Author_name.append(a.text)\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        Author_name.append(\"-\")\n",
    "        \n",
    "        \n",
    "     \n",
    "    try:    #Volumes_sold=[]\n",
    "        \n",
    "        for v in driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[\"+str(r)+\"]/td[4]\"):\n",
    "            Volumes_sold.append(v.text)\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        Volumes_sold.append(\"-\")\n",
    "            \n",
    "            \n",
    "    try:    #Publisher=[]\n",
    "        \n",
    "        for p in driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[\"+str(r)+\"]/td[5]\"):\n",
    "            Publisher.append(p.text)\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        Publisher.append(\"-\")     \n",
    "        \n",
    "        \n",
    "        \n",
    "    try:    #Genre=[]\n",
    "        \n",
    "        for g in driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[\"+str(r)+\"]/td[6]\"):\n",
    "            Genre.append(g.text)\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "         Genre.append(\"-\")\n",
    "       \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Book_name']=Book_name\n",
    "df['Author_name']=Author_name\n",
    "df['Volumes_sold']=Volumes_sold\n",
    "df['Publisher']=Publisher\n",
    "df['Genre']=Genre\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    " Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.imdb.com/list/ls095964455/ '\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "url=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='lister-item-image ribbonize']//a\"):\n",
    "    url.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range (1,101):\n",
    "    try:\n",
    "        n=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div[\"+str(r)+\"]/div[2]/h3/a\")\n",
    "        name.append(n.text)  \n",
    "    except NoSuchElementException:\n",
    "         name.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Year_span\n",
    "Year_span=[] \n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genre\n",
    "Genre=[]\n",
    "for g in driver.find_elements_by_class_name(\"genre\"):\n",
    "    Genre.append(g.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run_time=[]\n",
    "Run_time=[]\n",
    "for r in driver.find_elements_by_class_name(\"runtime\"):\n",
    "    Run_time.append(r.text)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='lister-item-image ribbonize']//a\"):\n",
    "    url.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"/html/body/div[4]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div[1]/div[2]/h3/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings=[]\n",
    "Votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url:\n",
    "    driver.get(i)\n",
    "    \n",
    "    try: #Ratings=[]\n",
    "        r=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[2]/div[5]/div[1]/div[2]/div/div[1]/div[2]/div/div[1]/div[1]/div[1]/strong/span\")\n",
    "        Ratings.append(r.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Ratings.append(\"_\")\n",
    "         \n",
    "    try: #Votes=[]\n",
    "        v=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[2]/div[5]/div[1]/div[2]/div/div[1]/div[2]/div/div[1]/div[1]/a/span\")\n",
    "        Votes.append(v.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Votes.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Name']=name\n",
    "df['Year span']=Year_span\n",
    "df['Genre']=Genre\n",
    "df['Run time']=Run_time\n",
    "df['Ratings']= Ratings\n",
    "df['Votes']=Votes\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    " Url = https://archive.ics.uci.edu/\n",
    " You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://archive.ics.uci.edu/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on view all data set\n",
    "driver.find_element_by_xpath(\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the row of the table\n",
    "row=(1+len(driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr\")))\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(2,row):\n",
    "    try:#Dataset_name\n",
    "        n=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[\"+str(r)+\"]/td[1]\")\n",
    "        Dataset_name.append(n.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append(\"-\")\n",
    "        \n",
    "        \n",
    "    try:#Data_type=[]\n",
    "        n=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[\"+str(r)+\"]/td[2]\")\n",
    "        Data_type.append(n.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Data_type.append(\"-\")\n",
    "       \n",
    "    try:#Task=[]\n",
    "        n=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[\"+str(r)+\"]/td[3]\")\n",
    "        Task.append(n.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Task.append(\"-\")\n",
    "        \n",
    "    try:#Attribute_type=[]\n",
    "        n=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[\"+str(r)+\"]/td[4]\")\n",
    "        Attribute_type.append(n.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append(\"-\")\n",
    "        \n",
    "        \n",
    "    try:#No_of_instances=[]\n",
    "        n=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[\"+str(r)+\"]/td[5]\")\n",
    "        No_of_instances.append(n.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append(\"-\")\n",
    "        \n",
    "        \n",
    "    try:#No_of_attribute=[]\n",
    "        n=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[\"+str(r)+\"]/td[6]\")\n",
    "        No_of_attribute.append(n.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        No_of_attribute.append(\"-\")\n",
    "        \n",
    "        \n",
    "    try:#Year=[]\n",
    "        n=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[\"+str(r)+\"]/td[7]\")\n",
    "        Year.append(n.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Year.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Dataset name']=Dataset_name\n",
    "df['Data type']=Data_type\n",
    "df['Task']=Task\n",
    "df['Attribute type']=Attribute_type\n",
    "df['No of instances']=No_of_instances\n",
    "df['No of attribute']=No_of_attribute\n",
    "df['Year']=Year\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
